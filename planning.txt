
1. User inputs repo (backend parses repo with git ingest + repo at each commit; maybe just diffs)
2. User enters query (how did function a change over time?). AI finds most relevant commit/diff and then does analysis
3. Maybe does some sort of rag for extra context on repo? TBD. Returns the information to user
4. Cooler if steps 2-3 done through voice (elevenlabs and openai whispr)

Why it's better than cursor:
- Cursor only has context for couple files
- Cursor only sees current code (not the choices made in commit)
- Speaking is faster/more efficient.

Extra: 
1. Automatically generated tour from beginning
2. Voice based navigation?


Notes:
Can't use full end to end integration elevenlabs (bc context window limitations for the API)
Probably will need to do api call to gpt with context of the source code, then ask questions, and read out loud the response. 